# 6001CEM_disseration 
_"Comparative Analysis on Single Classification Models Using SVM and CNN Algorithms for Speech Emotion Recognition Systems in Vehicles"_

## Abstract

Speech Emotion Recognition (SER) is essential for human-computer interaction as autonomous vehicles enter the industry. Human-vehicle collaboration is imperative not only for safety, but for user experience as well. SER data can assist the assessment of the driverâ€™s capabilities and behaviour in almost real-time. Therefore, comparative analysis of data, features and models assists the understanding of the process to select the most precise one. Thus, in this study the implications of machine learning techniques such data augmentation, conventional classification and artificial neural networks models are reviewed and assessed to later be compared and evaluated in order to reach the best fit when predicting emotions through speech signal in a driving environment.
Datasets such as IEMOCAP, TESS, CREMAD, SAVEE, Emo-DB were examined for speech feature extraction. The features extracted were Mel Frequency Cepstral Coefficients (MFCC), Chroma energy and Logarithmic Mel Spectrogram (LMS) to accommodate the data inputs requirements of the 1D and 2D CNN models. Several audio augmentation tools were used, and their efficacy tested. The raw data reached higher accuracies when implemented in a CNN 1D context. However, the noise injection outperformed it when applied to SVM. Later, audio classification models, SVM, LSTM and CNN, were considered individually and combined, which achieve accuracies between approximately 37% and 67%, with the CNN 2D+LSTM surpassing the rest.
